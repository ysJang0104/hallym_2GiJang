{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509d0512-87fb-4bbf-8002-b828099d4f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_array: (130, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "directory1 = \"apg파일/\"\n",
    "data = []\n",
    "\n",
    "# for i in range(5):\n",
    "#     min_data = i * 200  # 0, 200, 400, 600, 800\n",
    "#     max_data = min_data + 200  # 200, 400, 600, 800, 1000\n",
    "for root, dirs, files in os.walk(directory1):\n",
    "#     files.sort()\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            full_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(full_path, usecols=['APG Wave'])\n",
    "            series = df.values.flatten()[:200]  # max data\n",
    "            series = series.reshape(-1, 1)  # 1D -> 2D\n",
    "            scaler = MinMaxScaler()\n",
    "            series = scaler.fit_transform(series)\n",
    "            data.append(series)\n",
    "\n",
    "data_array = np.array(data)\n",
    "\n",
    "# y를 적절하게 수정 필요 (클래스 불균형 고려)\n",
    "\n",
    "print(\"Shape of data_array:\", data_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d297efe3-4eba-47ef-b380-675af46ed5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 엑셀 파일 불러오기 (엑셀 파일의 경로를 넣어야 합니다)\n",
    "df = pd.read_csv(\"2024-10-11 (11-00-32)-APG【 이기장 】.csv\")\n",
    "df_sorted = df.sort_values(by='TestDate')\n",
    "\n",
    "# 정렬된 데이터프레임을 확인\n",
    "# VasType 열의 모든 값에 3을 곱하기\n",
    "df_sorted['VasType'] = df_sorted['VasType'] * 3\n",
    "pd.set_option('display.max_rows', None)\n",
    "# 결과 확인\n",
    "import pandas as pd\n",
    "\n",
    "# 조건에 따른 VasType 값 조정 함수 정의\n",
    "def adjust_vastype(row):\n",
    "    if row['TypeLebel'] == '+++':\n",
    "        return row['VasType'] - 3\n",
    "    elif row['TypeLebel'] == '++':\n",
    "        return row['VasType'] - 2\n",
    "    elif row['TypeLebel'] == '+':\n",
    "        return row['VasType'] - 1\n",
    "    else:\n",
    "        return row['VasType']  # 조건에 맞지 않으면 변경하지 않음\n",
    "\n",
    "# apply 함수로 각 행에 대해 VasType 값을 조정\n",
    "df_sorted['VasType'] = df_sorted.apply(adjust_vastype, axis=1)\n",
    "\n",
    "# 결과 확인\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_sorted['VasType'].reset_index(drop=True,inplace=True)\n",
    "df_sorted['VasType'].value_counts()\n",
    "y = df_sorted['VasType'].values\n",
    "# y = np.tile(df_sorted['VasType'].values, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe65d835-4457-4fc8-b78b-535f9ea7cbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_array: (260, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "X_flipped = np.flip(data_array, axis=0)\n",
    "\n",
    "def adjust_amplitude(signal, factor=0.05):\n",
    "    # signal과 동일한 모양의 랜덤 값을 생성하여 진폭 조정\n",
    "    return signal * (1 + factor * np.random.uniform(-1, 1, signal.shape))\n",
    "\n",
    "adjusted_signal = adjust_amplitude(data_array, factor=0.05)\n",
    "adjusted_signal.shape\n",
    "\n",
    "X_adjusted=np.vstack((data_array, adjusted_signal))\n",
    "\n",
    "# 반전 데이터와 원본 데이터 결합\n",
    "X_augmented = np.vstack((data_array, X_flipped))  # X와 반전 데이터를 위아래로 결합\n",
    "y_augmented = np.concatenate((y, y)) \n",
    "\n",
    "print(\"Shape of data_array:\",X_adjusted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b1b4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 06:52:38.257848: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-15 06:52:38.275127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-15 06:52:38.295079: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-15 06:52:38.301185: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-15 06:52:38.317616: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-15 06:52:39.458210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import Conv1D, Dropout, Flatten, Dense, BatchNormalization, GlobalAveragePooling1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1f3907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 200) (564,)\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42, k_neighbors=2)\n",
    "X = X_adjusted.reshape(X_adjusted.shape[0], -1)  # (650, 200 * 1) 형태로 변환\n",
    "\n",
    "X_res, y_res = smote.fit_resample(X, y_augmented)\n",
    "print(X_res.shape, y_res.shape)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648fd346-19d0-4a3b-9413-b47683ea3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # 첫 번째 GPU만 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "db224e56",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.3547 - loss: 15.4578 - val_accuracy: 0.1868 - val_loss: 9.3057 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 6.1553 - val_accuracy: 0.2088 - val_loss: 6.1451 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 2.9793 - val_accuracy: 0.3297 - val_loss: 4.2834 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9364 - loss: 1.5507 - val_accuracy: 0.4176 - val_loss: 2.7617 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.9967 - val_accuracy: 0.6703 - val_loss: 1.5567 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9774 - loss: 0.5819 - val_accuracy: 0.7912 - val_loss: 1.4032 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9483 - loss: 0.5933 - val_accuracy: 0.8462 - val_loss: 1.3424 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9654 - loss: 0.4736 - val_accuracy: 0.7802 - val_loss: 1.2454 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9732 - loss: 0.3861 - val_accuracy: 0.8352 - val_loss: 0.8741 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.1981 - val_accuracy: 0.9011 - val_loss: 0.6839 - learning_rate: 0.0010\n",
      "Fold 1 validation accuracy: 90.11%\n",
      "Fold 2/5\n",
      "Epoch 1/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 0.3670 - loss: 15.5786 - val_accuracy: 0.1778 - val_loss: 9.0650 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7397 - loss: 5.9441 - val_accuracy: 0.1778 - val_loss: 6.4128 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8841 - loss: 2.5630 - val_accuracy: 0.1778 - val_loss: 5.3865 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8962 - loss: 1.4803 - val_accuracy: 0.1778 - val_loss: 5.4646 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9574 - loss: 0.7621 - val_accuracy: 0.2333 - val_loss: 3.6616 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9360 - loss: 0.6524 - val_accuracy: 0.5111 - val_loss: 1.8125 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9579 - loss: 0.4196 - val_accuracy: 0.4444 - val_loss: 1.8191 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9562 - loss: 0.3180 - val_accuracy: 0.6778 - val_loss: 1.1020 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9301 - loss: 0.5233 - val_accuracy: 0.8778 - val_loss: 0.8062 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9848 - loss: 0.2749 - val_accuracy: 0.7222 - val_loss: 1.7829 - learning_rate: 0.0010\n",
      "Fold 2 validation accuracy: 72.22%\n",
      "Fold 3/5\n",
      "Epoch 1/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.3692 - loss: 15.4181 - val_accuracy: 0.1556 - val_loss: 8.4653 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 5.8982 - val_accuracy: 0.2444 - val_loss: 5.2994 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9239 - loss: 2.7106 - val_accuracy: 0.1556 - val_loss: 3.7730 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9584 - loss: 1.4680 - val_accuracy: 0.1889 - val_loss: 2.8552 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9794 - loss: 0.7527 - val_accuracy: 0.5222 - val_loss: 1.9907 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.6297 - val_accuracy: 0.7444 - val_loss: 1.1205 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.9919 - val_accuracy: 0.7889 - val_loss: 1.0038 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.5484 - val_accuracy: 0.8667 - val_loss: 0.8179 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9469 - loss: 0.4868 - val_accuracy: 0.8667 - val_loss: 0.9206 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9628 - loss: 0.3804 - val_accuracy: 0.9111 - val_loss: 0.3972 - learning_rate: 0.0010\n",
      "Fold 3 validation accuracy: 91.11%\n",
      "Fold 4/5\n",
      "Epoch 1/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.3969 - loss: 15.2954 - val_accuracy: 0.1556 - val_loss: 8.3611 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7891 - loss: 5.8927 - val_accuracy: 0.3000 - val_loss: 4.8506 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8753 - loss: 2.7995 - val_accuracy: 0.3556 - val_loss: 3.2004 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8907 - loss: 1.6778 - val_accuracy: 0.3889 - val_loss: 2.3473 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9578 - loss: 0.7548 - val_accuracy: 0.4667 - val_loss: 1.7648 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9369 - loss: 0.6405 - val_accuracy: 0.8111 - val_loss: 0.9813 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9478 - loss: 0.4993 - val_accuracy: 0.8111 - val_loss: 0.8711 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9262 - loss: 0.5330 - val_accuracy: 0.9111 - val_loss: 0.8100 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9586 - loss: 0.3007 - val_accuracy: 0.8778 - val_loss: 0.8005 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9696 - loss: 0.2846 - val_accuracy: 0.8444 - val_loss: 1.0899 - learning_rate: 0.0010\n",
      "Fold 4 validation accuracy: 84.44%\n",
      "Fold 5/5\n",
      "Epoch 1/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 0.3571 - loss: 16.0007 - val_accuracy: 0.1111 - val_loss: 9.2404 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 6.3872 - val_accuracy: 0.1111 - val_loss: 5.9560 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 3.1740 - val_accuracy: 0.1333 - val_loss: 4.1390 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9399 - loss: 1.4710 - val_accuracy: 0.1556 - val_loss: 2.7453 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9351 - loss: 0.8725 - val_accuracy: 0.5667 - val_loss: 1.7290 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9677 - loss: 0.5241 - val_accuracy: 0.8444 - val_loss: 0.8271 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.4512 - val_accuracy: 0.9444 - val_loss: 0.5931 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9202 - loss: 0.5362 - val_accuracy: 0.9222 - val_loss: 0.4819 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.2746 - val_accuracy: 0.8556 - val_loss: 1.2590 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9428 - loss: 0.5570 - val_accuracy: 0.9333 - val_loss: 0.5586 - learning_rate: 0.0010\n",
      "Fold 5 validation accuracy: 93.33%\n",
      "평균 검증 정확도: 86.24%\n",
      "최종 모델이 'final_model.keras'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold 교차 검증\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 교차 검증 반복\n",
    "fold_val_accuracies = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), 1):\n",
    "    print(f\"Fold {fold}/{skf.get_n_splits()}\")\n",
    "\n",
    "    # 학습과 검증 데이터 분할\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # 모델 정의\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=5, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(32, kernel_size=8, activation='relu', kernel_regularizer=regularizers.l2(0.2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Conv1D(32, kernel_size=10, activation='relu', kernel_regularizer=regularizers.l2(0.3)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(18, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        validation_data=(X_val_fold, y_val_fold),\n",
    "        batch_size=4,\n",
    "        epochs=10,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 최종 검증 정확도 저장\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    fold_val_accuracies.append(val_accuracy)\n",
    "    print(f\"Fold {fold} validation accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "# 평균 검증 정확도 출력\n",
    "mean_val_accuracy = np.mean(fold_val_accuracies)\n",
    "print(f\"평균 검증 정확도: {mean_val_accuracy:.2%}\")\n",
    "\n",
    "# 최종 모델 저장 (최고 성능의 모델을 저장)\n",
    "best_model = model\n",
    "best_model.save('final_model-3.keras')\n",
    "print(\"최종 모델이 'final_model.keras'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3d6b66e9-cc48-4bd5-9244-8a90dae8ed36",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.4957 - loss: 14.5580 - val_accuracy: 0.1648 - val_loss: 8.8854 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8270 - loss: 5.2783 - val_accuracy: 0.1648 - val_loss: 5.5171 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8711 - loss: 2.5493 - val_accuracy: 0.1648 - val_loss: 4.4668 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 1.4097 - val_accuracy: 0.2418 - val_loss: 3.5336 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.8082 - val_accuracy: 0.2857 - val_loss: 3.0405 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9523 - loss: 0.5796 - val_accuracy: 0.8242 - val_loss: 1.1533 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9510 - loss: 0.4770 - val_accuracy: 0.8681 - val_loss: 0.7607 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9533 - loss: 0.3763 - val_accuracy: 0.8242 - val_loss: 0.9131 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9419 - loss: 0.3952 - val_accuracy: 0.8352 - val_loss: 1.4834 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.4209 - val_accuracy: 0.8791 - val_loss: 0.5025 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9691 - loss: 0.2730 - val_accuracy: 0.6813 - val_loss: 1.1881 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9801 - loss: 0.3524 - val_accuracy: 0.8791 - val_loss: 0.5395 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.2344 - val_accuracy: 0.8352 - val_loss: 0.8889 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9540 - loss: 0.3727 - val_accuracy: 0.9231 - val_loss: 0.7026 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9699 - loss: 0.2681 - val_accuracy: 0.9341 - val_loss: 0.5531 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9749 - loss: 0.2334 - val_accuracy: 0.9121 - val_loss: 0.5492 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1301 - val_accuracy: 0.8901 - val_loss: 0.4515 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0669 - val_accuracy: 0.8242 - val_loss: 0.5778 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0378 - val_accuracy: 0.7363 - val_loss: 0.9381 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0416 - val_accuracy: 0.8681 - val_loss: 0.9970 - learning_rate: 5.0000e-04\n",
      "Fold 1 validation accuracy: 86.81%\n",
      "Fold 2/5\n",
      "Epoch 1/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.3654 - loss: 15.3394 - val_accuracy: 0.1889 - val_loss: 8.3050 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7345 - loss: 5.9321 - val_accuracy: 0.1778 - val_loss: 5.0760 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8632 - loss: 2.7818 - val_accuracy: 0.1889 - val_loss: 4.5155 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9267 - loss: 1.3461 - val_accuracy: 0.2444 - val_loss: 2.9077 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9682 - loss: 0.7397 - val_accuracy: 0.4111 - val_loss: 2.0831 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9203 - loss: 0.6426 - val_accuracy: 0.7778 - val_loss: 0.9615 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9657 - loss: 0.4144 - val_accuracy: 0.6778 - val_loss: 1.0478 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.2340 - val_accuracy: 0.9556 - val_loss: 0.4127 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9757 - loss: 0.2548 - val_accuracy: 0.8667 - val_loss: 0.5705 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8894 - loss: 0.5557 - val_accuracy: 0.9000 - val_loss: 0.6185 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9710 - loss: 0.3154 - val_accuracy: 0.9333 - val_loss: 0.4294 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9931 - loss: 0.2014 - val_accuracy: 0.8111 - val_loss: 0.9023 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9432 - loss: 0.4402 - val_accuracy: 0.8333 - val_loss: 0.6407 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9979 - loss: 0.1446 - val_accuracy: 0.8000 - val_loss: 0.7186 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0666 - val_accuracy: 0.6000 - val_loss: 1.1446 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0339 - val_accuracy: 0.5333 - val_loss: 1.3090 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0386 - val_accuracy: 0.8111 - val_loss: 1.3142 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9901 - loss: 0.0896 - val_accuracy: 0.9444 - val_loss: 0.3234 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0410 - val_accuracy: 0.9333 - val_loss: 0.8451 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.1069 - val_accuracy: 0.9222 - val_loss: 0.4173 - learning_rate: 5.0000e-04\n",
      "Fold 2 validation accuracy: 92.22%\n",
      "Fold 3/5\n",
      "Epoch 1/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 73ms/step - accuracy: 0.4304 - loss: 15.1629 - val_accuracy: 0.1667 - val_loss: 8.4177 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7297 - loss: 5.7671 - val_accuracy: 0.2444 - val_loss: 4.7512 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8609 - loss: 2.5569 - val_accuracy: 0.1556 - val_loss: 3.3227 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9164 - loss: 1.2120 - val_accuracy: 0.3556 - val_loss: 2.4617 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9572 - loss: 0.6490 - val_accuracy: 0.3444 - val_loss: 1.8776 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9624 - loss: 0.4712 - val_accuracy: 0.5111 - val_loss: 1.3811 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9536 - loss: 0.3671 - val_accuracy: 0.8889 - val_loss: 0.4890 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9771 - loss: 0.2410 - val_accuracy: 0.9111 - val_loss: 0.4178 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9539 - loss: 0.4229 - val_accuracy: 0.7333 - val_loss: 1.7608 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9508 - loss: 0.4600 - val_accuracy: 0.7556 - val_loss: 0.7191 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9668 - loss: 0.2742 - val_accuracy: 0.9333 - val_loss: 0.7732 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9286 - loss: 0.4983 - val_accuracy: 0.9222 - val_loss: 0.4755 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9710 - loss: 0.3105 - val_accuracy: 0.9444 - val_loss: 0.6387 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.3722 - val_accuracy: 0.9556 - val_loss: 0.3214 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.1818 - val_accuracy: 0.8889 - val_loss: 0.3771 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0864 - val_accuracy: 0.8556 - val_loss: 0.5469 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0467 - val_accuracy: 0.8444 - val_loss: 0.5750 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0285 - val_accuracy: 0.5444 - val_loss: 4.1903 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9328 - loss: 0.3945 - val_accuracy: 0.9778 - val_loss: 0.3095 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1550 - val_accuracy: 0.9444 - val_loss: 0.2212 - learning_rate: 5.0000e-04\n",
      "Fold 3 validation accuracy: 94.44%\n",
      "Fold 4/5\n",
      "Epoch 1/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.3800 - loss: 15.9636 - val_accuracy: 0.1778 - val_loss: 9.0495 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7383 - loss: 6.4326 - val_accuracy: 0.3667 - val_loss: 5.3728 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 3.0282 - val_accuracy: 0.3333 - val_loss: 3.5687 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9433 - loss: 1.4086 - val_accuracy: 0.4889 - val_loss: 2.1381 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9556 - loss: 0.7474 - val_accuracy: 0.5444 - val_loss: 1.8318 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9325 - loss: 0.5760 - val_accuracy: 0.9000 - val_loss: 1.0871 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9344 - loss: 0.5465 - val_accuracy: 0.8889 - val_loss: 0.8253 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9672 - loss: 0.4044 - val_accuracy: 0.8556 - val_loss: 0.7491 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.2010 - val_accuracy: 0.9111 - val_loss: 0.6695 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.2792 - val_accuracy: 0.8556 - val_loss: 1.0129 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9642 - loss: 0.3924 - val_accuracy: 0.8778 - val_loss: 1.3814 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9754 - loss: 0.3392 - val_accuracy: 0.7222 - val_loss: 2.4771 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9418 - loss: 0.5060 - val_accuracy: 0.9111 - val_loss: 1.2362 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9550 - loss: 0.4460 - val_accuracy: 0.8111 - val_loss: 1.9062 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9591 - loss: 0.4928 - val_accuracy: 0.9333 - val_loss: 0.7530 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1868 - val_accuracy: 0.9111 - val_loss: 0.5233 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0949 - val_accuracy: 0.8889 - val_loss: 0.5118 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0546 - val_accuracy: 0.8778 - val_loss: 0.5216 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0396 - val_accuracy: 0.8889 - val_loss: 0.4535 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0227 - val_accuracy: 0.9000 - val_loss: 0.4558 - learning_rate: 5.0000e-04\n",
      "Fold 4 validation accuracy: 90.00%\n",
      "Fold 5/5\n",
      "Epoch 1/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.3358 - loss: 15.5365 - val_accuracy: 0.2333 - val_loss: 8.7845 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7304 - loss: 6.3559 - val_accuracy: 0.1111 - val_loss: 5.2935 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9024 - loss: 3.0272 - val_accuracy: 0.1333 - val_loss: 4.6836 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 2.0229 - val_accuracy: 0.3444 - val_loss: 3.0428 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8972 - loss: 1.2044 - val_accuracy: 0.3778 - val_loss: 2.4504 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9573 - loss: 0.5879 - val_accuracy: 0.4667 - val_loss: 1.8576 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8996 - loss: 0.6975 - val_accuracy: 0.9667 - val_loss: 0.5941 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9682 - loss: 0.3603 - val_accuracy: 0.9333 - val_loss: 0.5588 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9803 - loss: 0.3154 - val_accuracy: 0.7889 - val_loss: 0.6549 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9983 - loss: 0.1352 - val_accuracy: 0.8556 - val_loss: 0.6687 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9688 - loss: 0.2294 - val_accuracy: 0.9444 - val_loss: 0.9913 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8486 - loss: 0.8517 - val_accuracy: 0.9222 - val_loss: 1.0692 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9727 - loss: 0.4779 - val_accuracy: 0.9333 - val_loss: 0.5604 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9897 - loss: 0.2995 - val_accuracy: 0.9556 - val_loss: 0.3331 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9883 - loss: 0.1808 - val_accuracy: 0.8444 - val_loss: 0.4303 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0965 - val_accuracy: 0.8000 - val_loss: 0.5319 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0509 - val_accuracy: 0.7444 - val_loss: 0.7233 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0316 - val_accuracy: 0.9222 - val_loss: 0.3122 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0268 - val_accuracy: 0.9667 - val_loss: 0.1732 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0853 - val_accuracy: 0.9444 - val_loss: 0.4868 - learning_rate: 5.0000e-04\n",
      "Fold 5 validation accuracy: 94.44%\n",
      "평균 검증 정확도: 91.58%\n",
      "최종 모델이 'final_model.keras'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold 교차 검증\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 교차 검증 반복\n",
    "fold_val_accuracies = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), 1):\n",
    "    print(f\"Fold {fold}/{skf.get_n_splits()}\")\n",
    "\n",
    "    # 학습과 검증 데이터 분할\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # 모델 정의\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=5, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(32, kernel_size=8, activation='relu', kernel_regularizer=regularizers.l2(0.2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Conv1D(32, kernel_size=10, activation='relu', kernel_regularizer=regularizers.l2(0.3)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(18, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        validation_data=(X_val_fold, y_val_fold),\n",
    "        batch_size=4,\n",
    "        epochs=20,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 최종 검증 정확도 저장\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    fold_val_accuracies.append(val_accuracy)\n",
    "    print(f\"Fold {fold} validation accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "# 평균 검증 정확도 출력\n",
    "mean_val_accuracy = np.mean(fold_val_accuracies)\n",
    "print(f\"평균 검증 정확도: {mean_val_accuracy:.2%}\")\n",
    "\n",
    "# 최종 모델 저장 (최고 성능의 모델을 저장)\n",
    "best_model = model\n",
    "best_model.save('final_model-epoch20.keras')\n",
    "print(\"최종 모델이 'final_model.keras'로 저장되었습니다.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Mock data for demonstration purposes (replace these with actual history.history values)\n",
    "epochs = \n",
    "mock_loss = np.random.uniform(0.2, 1.0, epochs).cumsum() / np.arange(1, epochs + 1)\n",
    "mock_val_loss = np.random.uniform(0.2, 1.0, epochs).cumsum() / np.arange(1, epochs + 1)\n",
    "mock_accuracy = np.linspace(0.5, 0.9, epochs) + np.random.uniform(-0.05, 0.05, epochs)\n",
    "mock_val_accuracy = np.linspace(0.4, 0.8, epochs) + np.random.uniform(-0.05, 0.05, epochs)\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(range(1, epochs + 1), mock_loss, label='Train Loss')\n",
    "plt.plot(range(1, epochs + 1), mock_val_loss, label='Validation Loss', linestyle='--')\n",
    "plt.title('Model Loss and Accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(1, epochs + 1), mock_accuracy, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs + 1), mock_val_accuracy, label='Validation Accuracy', linestyle='--')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d17a6829-0cbf-499b-b6c0-d6d6464b16d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.2624 - loss: 16.7596 - val_accuracy: 0.1868 - val_loss: 10.7711 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6189 - loss: 9.0652 - val_accuracy: 0.1648 - val_loss: 7.2815 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7325 - loss: 5.6794 - val_accuracy: 0.2088 - val_loss: 5.3481 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7594 - loss: 3.8012 - val_accuracy: 0.2198 - val_loss: 4.1917 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8832 - loss: 2.4396 - val_accuracy: 0.2747 - val_loss: 3.3178 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8892 - loss: 1.7050 - val_accuracy: 0.2088 - val_loss: 2.8003 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8525 - loss: 1.4024 - val_accuracy: 0.4725 - val_loss: 2.1624 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8589 - loss: 1.2127 - val_accuracy: 0.5604 - val_loss: 1.7935 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8853 - loss: 0.9417 - val_accuracy: 0.7802 - val_loss: 1.2541 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9127 - loss: 0.6661 - val_accuracy: 0.8132 - val_loss: 1.0320 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9136 - loss: 0.5923 - val_accuracy: 0.7363 - val_loss: 1.1831 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8743 - loss: 0.6683 - val_accuracy: 0.8681 - val_loss: 0.9088 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9439 - loss: 0.4863 - val_accuracy: 0.8901 - val_loss: 0.6237 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9214 - loss: 0.4059 - val_accuracy: 0.8791 - val_loss: 0.6463 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9116 - loss: 0.4020 - val_accuracy: 0.8901 - val_loss: 0.8203 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9378 - loss: 0.4267 - val_accuracy: 0.8571 - val_loss: 1.1259 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9204 - loss: 0.5035 - val_accuracy: 0.9011 - val_loss: 1.2965 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9391 - loss: 0.4289 - val_accuracy: 0.9011 - val_loss: 0.9346 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9309 - loss: 0.4001 - val_accuracy: 0.9011 - val_loss: 0.9161 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9453 - loss: 0.3478 - val_accuracy: 0.9011 - val_loss: 0.6045 - learning_rate: 5.0000e-04\n",
      "Fold 1 validation accuracy: 90.11%\n",
      "Fold 2/5\n",
      "Epoch 1/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.2169 - loss: 17.4734 - val_accuracy: 0.1000 - val_loss: 11.6777 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5493 - loss: 9.4018 - val_accuracy: 0.1000 - val_loss: 8.0619 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6777 - loss: 5.7536 - val_accuracy: 0.1222 - val_loss: 6.0181 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7481 - loss: 3.7335 - val_accuracy: 0.1444 - val_loss: 4.9283 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7738 - loss: 2.5671 - val_accuracy: 0.2111 - val_loss: 4.1422 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7744 - loss: 1.9961 - val_accuracy: 0.1889 - val_loss: 3.5987 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7791 - loss: 1.4407 - val_accuracy: 0.2111 - val_loss: 2.8865 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8742 - loss: 1.0274 - val_accuracy: 0.2333 - val_loss: 2.5557 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8709 - loss: 0.9118 - val_accuracy: 0.6222 - val_loss: 1.4345 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8764 - loss: 0.9241 - val_accuracy: 0.6778 - val_loss: 1.0559 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9403 - loss: 0.5134 - val_accuracy: 0.9000 - val_loss: 0.6751 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9024 - loss: 0.5947 - val_accuracy: 0.9222 - val_loss: 0.4888 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9439 - loss: 0.4825 - val_accuracy: 0.9000 - val_loss: 0.5784 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9034 - loss: 0.4627 - val_accuracy: 0.8889 - val_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8196 - loss: 1.0061 - val_accuracy: 0.9000 - val_loss: 1.1157 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8956 - loss: 0.6381 - val_accuracy: 0.8889 - val_loss: 0.5922 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9196 - loss: 0.4581 - val_accuracy: 0.9111 - val_loss: 0.4910 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9081 - loss: 0.4146 - val_accuracy: 0.9333 - val_loss: 0.4582 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9559 - loss: 0.2747 - val_accuracy: 0.8889 - val_loss: 0.5040 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9638 - loss: 0.2550 - val_accuracy: 0.9111 - val_loss: 0.4228 - learning_rate: 5.0000e-04\n",
      "Fold 2 validation accuracy: 91.11%\n",
      "Fold 3/5\n",
      "Epoch 1/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.2028 - loss: 17.1746 - val_accuracy: 0.2111 - val_loss: 11.9839 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5544 - loss: 9.9118 - val_accuracy: 0.2111 - val_loss: 8.3459 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7111 - loss: 6.1482 - val_accuracy: 0.2111 - val_loss: 6.1522 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8193 - loss: 3.9537 - val_accuracy: 0.2111 - val_loss: 4.9051 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8177 - loss: 2.8372 - val_accuracy: 0.2111 - val_loss: 3.9242 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8431 - loss: 1.9805 - val_accuracy: 0.3889 - val_loss: 2.8591 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8514 - loss: 1.4629 - val_accuracy: 0.4889 - val_loss: 2.0702 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8994 - loss: 1.0975 - val_accuracy: 0.5778 - val_loss: 1.6549 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8935 - loss: 0.8218 - val_accuracy: 0.8444 - val_loss: 1.0054 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9320 - loss: 0.6608 - val_accuracy: 0.7444 - val_loss: 1.0618 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8733 - loss: 0.8113 - val_accuracy: 0.9000 - val_loss: 0.7361 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9157 - loss: 0.5896 - val_accuracy: 0.8667 - val_loss: 0.8181 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9073 - loss: 0.5713 - val_accuracy: 0.9111 - val_loss: 0.7195 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9200 - loss: 0.4617 - val_accuracy: 0.9222 - val_loss: 0.5824 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9314 - loss: 0.4756 - val_accuracy: 0.9111 - val_loss: 0.5845 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9272 - loss: 0.4972 - val_accuracy: 0.9000 - val_loss: 0.6278 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9086 - loss: 0.5099 - val_accuracy: 0.9333 - val_loss: 0.6296 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9386 - loss: 0.4602 - val_accuracy: 0.9222 - val_loss: 0.6485 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9554 - loss: 0.4264 - val_accuracy: 0.9222 - val_loss: 0.5721 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9157 - loss: 0.4837 - val_accuracy: 0.9556 - val_loss: 0.6214 - learning_rate: 0.0010\n",
      "Fold 3 validation accuracy: 95.56%\n",
      "Fold 4/5\n",
      "Epoch 1/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.1713 - loss: 17.1980 - val_accuracy: 0.1333 - val_loss: 11.3012 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6015 - loss: 9.3060 - val_accuracy: 0.2000 - val_loss: 7.6407 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7492 - loss: 5.5783 - val_accuracy: 0.1667 - val_loss: 5.4524 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7918 - loss: 3.6341 - val_accuracy: 0.2778 - val_loss: 4.1258 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7937 - loss: 2.4586 - val_accuracy: 0.3778 - val_loss: 3.7236 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8222 - loss: 1.6863 - val_accuracy: 0.4000 - val_loss: 2.5725 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8642 - loss: 1.2542 - val_accuracy: 0.5556 - val_loss: 2.0695 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7974 - loss: 1.2324 - val_accuracy: 0.7556 - val_loss: 1.3844 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7900 - loss: 1.2844 - val_accuracy: 0.8556 - val_loss: 1.1615 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9110 - loss: 0.7170 - val_accuracy: 0.8556 - val_loss: 1.0136 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8861 - loss: 0.6031 - val_accuracy: 0.8778 - val_loss: 0.7870 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9067 - loss: 0.4910 - val_accuracy: 0.8667 - val_loss: 0.7262 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8701 - loss: 0.7209 - val_accuracy: 0.8889 - val_loss: 1.0771 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9196 - loss: 0.5598 - val_accuracy: 0.9222 - val_loss: 1.0013 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9141 - loss: 0.4659 - val_accuracy: 0.8889 - val_loss: 0.8037 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9114 - loss: 0.4646 - val_accuracy: 0.9222 - val_loss: 1.2966 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9154 - loss: 0.4457 - val_accuracy: 0.9222 - val_loss: 0.8608 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9419 - loss: 0.3488 - val_accuracy: 0.9222 - val_loss: 0.5675 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9304 - loss: 0.3515 - val_accuracy: 0.9111 - val_loss: 0.5372 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9643 - loss: 0.2502 - val_accuracy: 0.9222 - val_loss: 0.5048 - learning_rate: 5.0000e-04\n",
      "Fold 4 validation accuracy: 92.22%\n",
      "Fold 5/5\n",
      "Epoch 1/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.2429 - loss: 16.7918 - val_accuracy: 0.1333 - val_loss: 11.2517 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5406 - loss: 9.0914 - val_accuracy: 0.1333 - val_loss: 7.7531 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7372 - loss: 5.3221 - val_accuracy: 0.1333 - val_loss: 5.8403 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7163 - loss: 3.4604 - val_accuracy: 0.1333 - val_loss: 5.1922 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7394 - loss: 2.3550 - val_accuracy: 0.1556 - val_loss: 3.7709 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7933 - loss: 1.7346 - val_accuracy: 0.3111 - val_loss: 2.6499 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8409 - loss: 1.2564 - val_accuracy: 0.1556 - val_loss: 2.8278 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8435 - loss: 0.9281 - val_accuracy: 0.3111 - val_loss: 2.1872 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9338 - loss: 0.6071 - val_accuracy: 0.3000 - val_loss: 2.2452 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8700 - loss: 0.7834 - val_accuracy: 0.9333 - val_loss: 0.7881 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9200 - loss: 0.5881 - val_accuracy: 0.6889 - val_loss: 1.1087 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8950 - loss: 0.6150 - val_accuracy: 0.9000 - val_loss: 0.7662 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8772 - loss: 0.6137 - val_accuracy: 0.9667 - val_loss: 0.6127 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9447 - loss: 0.4163 - val_accuracy: 0.9222 - val_loss: 0.7074 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8955 - loss: 0.5695 - val_accuracy: 0.9444 - val_loss: 0.5836 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9048 - loss: 0.4632 - val_accuracy: 0.9333 - val_loss: 0.6473 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8917 - loss: 0.6057 - val_accuracy: 0.9667 - val_loss: 0.5668 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9098 - loss: 0.5039 - val_accuracy: 0.9667 - val_loss: 0.5035 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9369 - loss: 0.4073 - val_accuracy: 0.9556 - val_loss: 0.6479 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9643 - loss: 0.3738 - val_accuracy: 0.9222 - val_loss: 0.5027 - learning_rate: 0.0010\n",
      "Fold 5 validation accuracy: 92.22%\n",
      "평균 검증 정확도: 92.24%\n",
      "최종 모델이 'final_model_epoch_20241117.keras'로 저장되었습니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold 교차 검증\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 교차 검증 반복\n",
    "fold_val_accuracies = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), 1):\n",
    "    print(f\"Fold {fold}/{skf.get_n_splits()}\")\n",
    "\n",
    "    # 학습과 검증 데이터 분할\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # 모델 정의\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=5, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Conv1D(32, kernel_size=8, activation='relu', kernel_regularizer=regularizers.l2(0.2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Conv1D(32, kernel_size=10, activation='relu', kernel_regularizer=regularizers.l2(0.3)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(18, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        validation_data=(X_val_fold, y_val_fold),\n",
    "        batch_size=6,\n",
    "        epochs=20,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 최종 검증 정확도 저장\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    fold_val_accuracies.append(val_accuracy)\n",
    "    print(f\"Fold {fold} validation accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "# 평균 검증 정확도 출력\n",
    "mean_val_accuracy = np.mean(fold_val_accuracies)\n",
    "print(f\"평균 검증 정확도: {mean_val_accuracy:.2%}\")\n",
    "\n",
    "# 최종 모델 저장 (최고 성능의 모델을 저장)\n",
    "best_model = model\n",
    "best_model.save('final_model_epoch_20241117_1.keras')\n",
    "print(\"최종 모델이 'final_model_epoch_20241117.keras'로 저장되었습니다.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Mock data for demonstration purposes (replace these with actual history.history values)\n",
    "epochs = 20\n",
    "mock_loss = np.random.uniform(0.2, 1.0, epochs).cumsum() / np.arange(1, epochs + 1)\n",
    "mock_val_loss = np.random.uniform(0.2, 1.0, epochs).cumsum() / np.arange(1, epochs + 1)\n",
    "mock_accuracy = np.linspace(0.5, 0.9, epochs) + np.random.uniform(-0.05, 0.05, epochs)\n",
    "mock_val_accuracy = np.linspace(0.4, 0.8, epochs) + np.random.uniform(-0.05, 0.05, epochs)\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(range(1, epochs + 1), mock_loss, label='Train Loss')\n",
    "plt.plot(range(1, epochs + 1), mock_val_loss, label='Validation Loss', linestyle='--')\n",
    "plt.title('Model Loss and Accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(1, epochs + 1), mock_accuracy, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs + 1), mock_val_accuracy, label='Validation Accuracy', linestyle='--')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7bd990b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 5 0 1 0 2 5 3 2 2 5 0 1 1 4 1 3 4 5 4 4 1 4 2 4 5 2 0 4 5 5 5 0 5 0 0\n",
      " 3 5 5 0 4 0 5 2 3 0 2 2 4 1 5 0 5 4 4 3 4 3 1 0 1 2 5 4 3 0 0 5 3 1 5 0 5\n",
      " 2 1 5 2 4 0 3 0 2 5 0 4 4 1 4 4]\n",
      "[0 4 1 4 1 0 2 5 0 1 0 3 4 0 3 4 2 5 4 1 3 3 4 3 1 3 4 5 4 5 1 1 1 1 4 3 2\n",
      " 3 5 3 3 5 5 2 1 1 2 4 3 1 2 1 0 5 2 2 5 5 1 5 5 0 1 2 4 5 5 1 0 0 0 2 1 1\n",
      " 0 4 2 0 1 3 0 0 4 5 0 1 3 4 3 0 0 1 0 1 2 4 4 5 1 3 3 3 4 2 4 4 1 2 5 2 0\n",
      " 2 5 4 0 0 3 1 3 4 0 1 1 5 4 1 4 4 2 4 0 5 1 0 4 5 3 3 2 3 1 1 4 0 0 1 4 0\n",
      " 3 1 3 4 3 2 0 0 4 4 2 0 3 1 3 4 2 1 3 4 3 0 4 5 2 3 3 2 2 4 2 1 5 5 0 2 3\n",
      " 5 3 0 5 1 2 4 4 1 0 4 5 2 5 2 2 0 0 4 3 1 0 2 4 0 3 1 2 2 1 0 5 5 1 2 2 4\n",
      " 3 1 0 3 2 1 4 2 5 2 1 2 5 5 2 5 1 2 4 1 5 3 4 5 4 2 2 3 5 0 4 4 5 5 3 4 0\n",
      " 3 3 2 3 2 0 3 2 1 4 4 0 2 2 3 2 1 0 3 1 1 0 5 0 2 2 2 3 2 0 5 1 1 2 0 5 3\n",
      " 4 4 5 0 1 0 5 4 3 1 3 4 1 0 0 1 3 2 3 5 1 3 2 4 1 1 5 4 4 2 3 1 1 2 5 0 2\n",
      " 5 5 5 5 1 3 4 5 1 4 4 0 4 0 3 2 2 1 1 4 2 4 0 3 3 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_val_fold)\n",
    "print(y_train_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7f80c06-41c1-40b6-a881-e25f219091d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">802,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,170</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_38 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_39 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m12,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_19 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m802,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │         \u001b[38;5;34m1,170\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,451,000</span> (9.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,451,000\u001b[0m (9.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">816,914</span> (3.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m816,914\u001b[0m (3.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,633,830</span> (6.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,633,830\u001b[0m (6.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델 로드\n",
    "loaded_model = load_model('final_model.keras')\n",
    "\n",
    "# 모델 요약 보기 (선택 사항)\n",
    "loaded_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc197ee4-cda5-46fa-b8f5-fd65147ad4e5",
   "metadata": {},
   "source": [
    "test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2959428c-36f0-4e92-87cc-a9a6868d2b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 (15-43-28) [30][kshyj][남][23] APG_Wave【 이기장 】.csv\n",
      "0 \n",
      "\n",
      "2024-10-19 (13-28-22) [29][김나영][여][21] APG_Wave【 이기장 】.csv\n",
      "1 \n",
      "\n",
      "2024-11-17 (15-44-23) [30][kshyj][남][23] APG_Wave【 이기장 】.csv\n",
      "2 \n",
      "\n",
      "2024-10-19 (13-28-49) [29][김나영][여][21] APG_Wave【 이기장 】.csv\n",
      "3 \n",
      "\n",
      "2024-10-19 (13-29-21) [29][김나영][여][21] APG_Wave【 이기장 】.csv\n",
      "4 \n",
      "\n",
      "2024-10-16 (14-20-41) [26][test][남][23] APG_Wave【 이기장 】.csv\n",
      "5 \n",
      "\n",
      "2024-11-17 (15-39-58) [30][kshyj][남][23] APG_Wave【 이기장 】.csv\n",
      "6 \n",
      "\n",
      "2024-10-16 (14-21-06) [26][test][남][23] APG_Wave【 이기장 】.csv\n",
      "7 \n",
      "\n",
      "2024-10-16 (14-21-37) [26][test][남][23] APG_Wave【 이기장 】.csv\n",
      "8 \n",
      "\n",
      "2024-10-19 (13-27-51) [29][김나영][여][21] APG_Wave【 이기장 】.csv\n",
      "9 \n",
      "\n",
      "2024-11-17 (15-43-08) [30][kshyj][남][23] APG_Wave【 이기장 】.csv\n",
      "10 \n",
      "\n",
      "2024-10-16 (14-20-08) [26][test][남][23] APG_Wave【 이기장 】.csv\n",
      "11 \n",
      "\n",
      "2024-10-16 (14-22-13) [26][test][남][23] APG_Wave【 이기장 】.csv\n",
      "12 \n",
      "\n",
      "2024-11-17 (15-43-54) [30][kshyj][남][23] APG_Wave【 이기장 】.csv\n",
      "13 \n",
      "\n",
      "2024-10-19 (13-30-08) [29][김나영][여][21] APG_Wave【 이기장 】.csv\n",
      "14 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "directory1 = \"test_apg/\"\n",
    "data = []\n",
    "\n",
    "# for i in range(5):\n",
    "#     min_data = i * 200  # 0, 200, 400, 600, 800\n",
    "#     max_data = min_data + 200  # 200, 400, 600, 800, 1000\n",
    "for root, dirs, files in os.walk(directory1):\n",
    "#     files.sort()\n",
    "    i=0\n",
    "    for file in files:\n",
    "        \n",
    "        if file.endswith(\".csv\"):\n",
    "            \n",
    "            full_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(full_path, usecols=['APG Wave'])\n",
    "            series = df.values.flatten()[:200]  # max data\n",
    "            series = series.reshape(-1, 1)  # 1D -> 2D\n",
    "            scaler = MinMaxScaler()\n",
    "            series = scaler.fit_transform(series)\n",
    "            data.append(series)\n",
    "            print(file)\n",
    "            print(i,\"\\n\")\n",
    "            i+=1\n",
    "\n",
    "\n",
    "data_array = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae0fe523-c703-4379-8cd9-2340a1704772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels as list: [5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4]\n",
      "Labels as numpy array: [5 4 4 4 4 4 4 4 4 4 4 3 3 4 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 숫자를 문자열로 변환하여 각 자리수를 리스트로 만듦\n",
    "number = 544444444443344\n",
    "labels = [int(digit) for digit in str(number)]\n",
    "\n",
    "# Numpy 배열로 변환 (필요하면)\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Labels as list:\", labels)\n",
    "print(\"Labels as numpy array:\", labels_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff0fc88a-4d1a-4c8b-9ab8-da5d1e9fd82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step - accuracy: 0.1333 - loss: 15.4898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
      "일치 여부 (True/False): [False False False False False False False False False False False  True\n",
      "  True False False]\n",
      "정확도: 13.33%\n",
      "[4 0 3 0 3 1 0 1 1 3 2 3 3 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 저장된 모델 로드\n",
    "model = load_model('학습률75.56%.keras')\n",
    "\n",
    "# 테스트 데이터 로드 (예시)\n",
    "# X_test와 y_test는 미리 준비되어야 합니다.\n",
    "X_test= data_array \n",
    "y_test = labels_array\n",
    "# X_test와 y_test를 적절히 전처리한 상태로 준비하세요.\n",
    "\n",
    "# 모델 테스트\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 두 배열 요소별 비교 (일치 여부)\n",
    "comparison = y_pred == y_test\n",
    "\n",
    "# True의 비율 계산 (정확도 확인)\n",
    "accuracy = np.mean(comparison)\n",
    "\n",
    "print(\"일치 여부 (True/False):\", comparison)\n",
    "print(f\"정확도: {accuracy:.2%}\")\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
